{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.2.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf_encrypted as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class\n",
    "\n",
    "class LogisticRegression:\n",
    "  \"\"\"Contains methods to build and train logistic regression.\"\"\"\n",
    "  def __init__(self, num_features):\n",
    "    self.w = tfe.define_private_variable(\n",
    "        tf.random_uniform([num_features, 1], -0.01, 0.01))\n",
    "    self.w_masked = tfe.mask(self.w)\n",
    "    self.b = tfe.define_private_variable(tf.zeros([1]))\n",
    "    self.b_masked = tfe.mask(self.b)\n",
    "\n",
    "  @property\n",
    "  def weights(self):\n",
    "    return self.w, self.b\n",
    "\n",
    "  def forward(self, x):\n",
    "    with tf.name_scope(\"forward\"):\n",
    "      out = tfe.matmul(x, self.w_masked) + self.b_masked\n",
    "      y = tfe.sigmoid(out)\n",
    "      return y\n",
    "\n",
    "  def backward(self, x, dy, learning_rate=0.01):\n",
    "    batch_size = x.shape.as_list()[0]\n",
    "    with tf.name_scope(\"backward\"):\n",
    "      dw = tfe.matmul(tfe.transpose(x), dy) / batch_size\n",
    "      db = tfe.reduce_sum(dy, axis=0) / batch_size\n",
    "      assign_ops = [\n",
    "          tfe.assign(self.w, self.w - dw * learning_rate),\n",
    "          tfe.assign(self.b, self.b - db * learning_rate),\n",
    "      ]\n",
    "      return assign_ops\n",
    "\n",
    "  def loss_grad(self, y, y_hat):\n",
    "    with tf.name_scope(\"loss-grad\"):\n",
    "      dy = y_hat - y\n",
    "      return dy\n",
    "\n",
    "  def fit_batch(self, x, y):\n",
    "    with tf.name_scope(\"fit-batch\"):\n",
    "      y_hat = self.forward(x)\n",
    "      dy = self.loss_grad(y, y_hat)\n",
    "      fit_batch_op = self.backward(x, dy)\n",
    "      return fit_batch_op\n",
    "\n",
    "  def fit(self, sess, x, y, num_batches):\n",
    "    fit_batch_op = self.fit_batch(x, y)\n",
    "    for batch in range(num_batches):\n",
    "      print(\"Batch {0: >4d}\".format(batch))\n",
    "      sess.run(fit_batch_op, tag='fit-batch')\n",
    "\n",
    "  def evaluate(self, sess, x, y, data_owner):\n",
    "    \"\"\"Return the accuracy\"\"\"\n",
    "    def print_accuracy(y_hat, y) -> tf.Operation:\n",
    "      with tf.name_scope(\"print-accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.round(y_hat), y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        print_op = tf.print(\"Accuracy on {}:\".format(data_owner.player_name),\n",
    "                            accuracy)\n",
    "        return print_op\n",
    "\n",
    "    with tf.name_scope(\"evaluate\"):\n",
    "      y_hat = self.forward(x)\n",
    "      print_accuracy_op = tfe.define_output(data_owner.player_name,\n",
    "                                            [y_hat, y],\n",
    "                                            print_accuracy)\n",
    "\n",
    "    sess.run(print_accuracy_op, tag='evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data owner class\n",
    "\n",
    "class DataOwner:\n",
    "  \"\"\"Contains code meant to be executed by a data owner Player.\"\"\"\n",
    "  def __init__(\n",
    "      self,\n",
    "      player_name,\n",
    "      num_features,\n",
    "      training_set_size,\n",
    "      test_set_size,\n",
    "      batch_size\n",
    "  ):\n",
    "    self.player_name = player_name\n",
    "    self.num_features = num_features\n",
    "    self.training_set_size = training_set_size\n",
    "    self.test_set_size = test_set_size\n",
    "    self.batch_size = batch_size\n",
    "    self.train_initializer = None\n",
    "    self.test_initializer = None\n",
    "\n",
    "  @property\n",
    "  def initializer(self):\n",
    "    return tf.group(self.train_initializer, self.test_initializer)\n",
    "\n",
    "  @tfe.local_computation\n",
    "  def provide_training_data(self):\n",
    "    \"\"\"Preprocess training dataset\n",
    "\n",
    "    Return single batch of training dataset\n",
    "    \"\"\"\n",
    "    def norm(x, y):\n",
    "      return tf.cast(x, tf.float32), tf.expand_dims(y, 0)\n",
    "\n",
    "    x_raw = tf.random.uniform(\n",
    "        minval=-.5,\n",
    "        maxval=.5,\n",
    "        shape=[self.training_set_size, self.num_features])\n",
    "\n",
    "    y_raw = tf.cast(tf.reduce_mean(x_raw, axis=1) > 0, dtype=tf.float32)\n",
    "\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((x_raw, y_raw)) \\\n",
    "        .map(norm) \\\n",
    "        .repeat() \\\n",
    "        .shuffle(buffer_size=self.batch_size) \\\n",
    "        .batch(self.batch_size)\n",
    "\n",
    "    train_set_iterator = train_set.make_initializable_iterator()\n",
    "    self.train_initializer = train_set_iterator.initializer\n",
    "\n",
    "    x, y = train_set_iterator.get_next()\n",
    "    x = tf.reshape(x, [self.batch_size, self.num_features])\n",
    "    y = tf.reshape(y, [self.batch_size, 1])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "  @tfe.local_computation\n",
    "  def provide_testing_data(self):\n",
    "    \"\"\"Preprocess testing dataset\n",
    "\n",
    "    Return single batch of testing dataset\n",
    "    \"\"\"\n",
    "    def norm(x, y):\n",
    "      return tf.cast(x, tf.float32), tf.expand_dims(y, 0)\n",
    "\n",
    "    x_raw = tf.random.uniform(\n",
    "        minval=-.5,\n",
    "        maxval=.5,\n",
    "        shape=[self.test_set_size, self.num_features])\n",
    "\n",
    "    y_raw = tf.cast(tf.reduce_mean(x_raw, axis=1) > 0, dtype=tf.float32)\n",
    "\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((x_raw, y_raw)) \\\n",
    "        .map(norm) \\\n",
    "        .batch(self.test_set_size)\n",
    "\n",
    "    test_set_iterator = test_set.make_initializable_iterator()\n",
    "    self.test_initializer = test_set_iterator.initializer\n",
    "\n",
    "    x, y = test_set_iterator.get_next()\n",
    "    x = tf.reshape(x, [self.test_set_size, self.num_features])\n",
    "    y = tf.reshape(y, [self.test_set_size, 1])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## class for model owner\n",
    "\n",
    "class ModelOwner:\n",
    "  \"\"\"Contains code meant to be executed by a model owner Player.\"\"\"\n",
    "  def __init__(self, player_name):\n",
    "    self.player_name = player_name\n",
    "\n",
    "  @tfe.local_computation\n",
    "  def receive_weights(self, *weights):\n",
    "    return tf.print(\"Weights on {}:\".format(self.player_name), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction client\n",
    "\n",
    "class PredictionClient:\n",
    "  \"\"\"Contains methods meant to be executed by a prediction client.\"\"\"\n",
    "  def __init__(self, player_name, num_features):\n",
    "    self.player_name = player_name\n",
    "    self.num_features = num_features\n",
    "\n",
    "  @tfe.local_computation\n",
    "  def provide_input(self):\n",
    "    return tf.random.uniform(\n",
    "        minval=-.5,\n",
    "        maxval=.5,\n",
    "        dtype=tf.float32,\n",
    "        shape=[1, self.num_features])\n",
    "\n",
    "  @tfe.local_computation\n",
    "  def receive_output(self, result):\n",
    "    return tf.print(\"Result on {}:\".format(self.player_name), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dummy data preparation for logistic regression training.\"\"\"\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def norm(x: tf.Tensor, y: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "  return tf.cast(x, tf.float32), tf.expand_dims(y, 0)\n",
    "\n",
    "\n",
    "def gen_training_input(total_size, nb_feats, batch_size):\n",
    "  \"\"\"Generate random data for training.\"\"\"\n",
    "  x_np = np.random.uniform(-.5, .5, size=[total_size, nb_feats])\n",
    "  y_np = np.array(x_np.mean(axis=1) > 0, np.float32)\n",
    "  train_set = tf.data.Dataset.from_tensor_slices((x_np, y_np)) \\\n",
    "                             .map(norm) \\\n",
    "                             .shuffle(buffer_size=100) \\\n",
    "                             .repeat() \\\n",
    "                             .batch(batch_size)\n",
    "  train_set_iterator = train_set.make_one_shot_iterator()\n",
    "  x, y = train_set_iterator.get_next()\n",
    "  x = tf.reshape(x, [batch_size, nb_feats])\n",
    "  y = tf.reshape(y, [batch_size, 1])\n",
    "\n",
    "  # tf.print(x, data=[x], message=\"x: \", summarize=6)\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def gen_test_input(total_size, nb_feats, batch_size):\n",
    "  \"\"\"Generate random data for evaluation.\"\"\"\n",
    "  x_test_np = np.random.uniform(-.5, .5, size=[total_size, nb_feats])\n",
    "  y_test_np = np.array(x_test_np.mean(axis=1) > 0, np.float32)\n",
    "  test_set = tf.data.Dataset.from_tensor_slices((x_test_np, y_test_np)) \\\n",
    "                            .map(norm) \\\n",
    "                            .batch(batch_size)\n",
    "  test_set_iterator = test_set.make_one_shot_iterator()\n",
    "  x_test, y_test = test_set_iterator.get_next()\n",
    "  x_test = tf.reshape(x_test, [batch_size, nb_feats])\n",
    "  y_test = tf.reshape(y_test, [batch_size, 1])\n",
    "\n",
    "  return x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-c974b9a6ed1a>:47: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\tensor\\native.py:101: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\config.py:171: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\config.py:84: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\tensor\\native.py:445: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Batch    0\n",
      "Batch    1\n",
      "Batch    2\n",
      "Batch    3\n",
      "Batch    4\n",
      "Batch    5\n",
      "Batch    6\n",
      "Batch    7\n",
      "Batch    8\n",
      "Batch    9\n",
      "Batch   10\n",
      "Batch   11\n",
      "Batch   12\n",
      "Batch   13\n",
      "Batch   14\n",
      "Batch   15\n",
      "Batch   16\n",
      "Batch   17\n",
      "Batch   18\n",
      "Batch   19\n",
      "Batch   20\n",
      "Batch   21\n",
      "Batch   22\n",
      "Batch   23\n",
      "Batch   24\n",
      "Batch   25\n",
      "Batch   26\n",
      "Batch   27\n",
      "Batch   28\n",
      "Batch   29\n",
      "Batch   30\n",
      "Batch   31\n",
      "Batch   32\n",
      "Batch   33\n",
      "Batch   34\n",
      "Batch   35\n",
      "Batch   36\n",
      "Batch   37\n",
      "Batch   38\n",
      "Batch   39\n",
      "Batch   40\n",
      "Batch   41\n",
      "Batch   42\n",
      "Batch   43\n",
      "Batch   44\n",
      "Batch   45\n",
      "Batch   46\n",
      "Batch   47\n",
      "Batch   48\n",
      "Batch   49\n",
      "Batch   50\n",
      "Batch   51\n",
      "Batch   52\n",
      "Batch   53\n",
      "Batch   54\n",
      "Batch   55\n",
      "Batch   56\n",
      "Batch   57\n",
      "Batch   58\n",
      "Batch   59\n",
      "Batch   60\n",
      "Batch   61\n",
      "Batch   62\n",
      "Batch   63\n",
      "Batch   64\n",
      "Batch   65\n",
      "Batch   66\n",
      "Batch   67\n",
      "Batch   68\n",
      "Batch   69\n",
      "Batch   70\n",
      "Batch   71\n",
      "Batch   72\n",
      "Batch   73\n",
      "Batch   74\n",
      "Batch   75\n",
      "Batch   76\n",
      "Batch   77\n",
      "Batch   78\n",
      "Batch   79\n",
      "Batch   80\n",
      "Batch   81\n",
      "Batch   82\n",
      "Batch   83\n",
      "Batch   84\n",
      "Batch   85\n",
      "Batch   86\n",
      "Batch   87\n",
      "Batch   88\n",
      "Batch   89\n",
      "Batch   90\n",
      "Batch   91\n",
      "Batch   92\n",
      "Batch   93\n",
      "Batch   94\n",
      "Batch   95\n",
      "Batch   96\n",
      "Batch   97\n",
      "Batch   98\n",
      "Batch   99\n",
      "Batch  100\n",
      "Batch  101\n",
      "Batch  102\n",
      "Batch  103\n",
      "Batch  104\n",
      "Batch  105\n",
      "Batch  106\n",
      "Batch  107\n",
      "Batch  108\n",
      "Batch  109\n",
      "Batch  110\n",
      "Batch  111\n",
      "Batch  112\n",
      "Batch  113\n",
      "Batch  114\n",
      "Batch  115\n",
      "Batch  116\n",
      "Batch  117\n",
      "Batch  118\n",
      "Batch  119\n",
      "Batch  120\n",
      "Batch  121\n",
      "Batch  122\n",
      "Batch  123\n",
      "Batch  124\n",
      "Batch  125\n",
      "Batch  126\n",
      "Batch  127\n",
      "Batch  128\n",
      "Batch  129\n",
      "Batch  130\n",
      "Batch  131\n",
      "Batch  132\n",
      "Batch  133\n",
      "Batch  134\n",
      "Batch  135\n",
      "Batch  136\n",
      "Batch  137\n",
      "Batch  138\n",
      "Batch  139\n",
      "Batch  140\n",
      "Batch  141\n",
      "Batch  142\n",
      "Batch  143\n",
      "Batch  144\n",
      "Batch  145\n",
      "Batch  146\n",
      "Batch  147\n",
      "Batch  148\n",
      "Batch  149\n",
      "Batch  150\n",
      "Batch  151\n",
      "Batch  152\n",
      "Batch  153\n",
      "Batch  154\n",
      "Batch  155\n",
      "Batch  156\n",
      "Batch  157\n",
      "Batch  158\n",
      "Batch  159\n",
      "Batch  160\n",
      "Batch  161\n",
      "Batch  162\n",
      "Batch  163\n",
      "Batch  164\n",
      "Batch  165\n",
      "Batch  166\n",
      "Batch  167\n",
      "Batch  168\n",
      "Batch  169\n",
      "Batch  170\n",
      "Batch  171\n",
      "Batch  172\n",
      "Batch  173\n",
      "Batch  174\n",
      "Batch  175\n",
      "Batch  176\n",
      "Batch  177\n",
      "Batch  178\n",
      "Batch  179\n",
      "Batch  180\n",
      "Batch  181\n",
      "Batch  182\n",
      "Batch  183\n",
      "Batch  184\n",
      "Batch  185\n",
      "Batch  186\n",
      "Batch  187\n",
      "Batch  188\n",
      "Batch  189\n",
      "Batch  190\n",
      "Batch  191\n",
      "Batch  192\n",
      "Batch  193\n",
      "Batch  194\n",
      "Batch  195\n",
      "Batch  196\n",
      "Batch  197\n",
      "Batch  198\n",
      "Batch  199\n",
      "Accuracy on data-owner-0: 0.89\n",
      "Accuracy on data-owner-1: 0.92\n",
      "Weights on model-owner: (([[0.076969974089315649]\n",
      " [0.0728547477518671]\n",
      " [0.0762078951379363]\n",
      " ...\n",
      " [0.054869684499314134]\n",
      " [0.0661484529797287]\n",
      " [0.065691205608901085]], [0.028044505410760555]),)\n"
     ]
    }
   ],
   "source": [
    "num_features = 10\n",
    "training_set_size = 2000\n",
    "test_set_size = 100\n",
    "batch_size = 100\n",
    "num_batches = (training_set_size // batch_size) * 10\n",
    "\n",
    "model_owner = ModelOwner('model-owner')\n",
    "data_owner_0 = DataOwner('data-owner-0',\n",
    "                         num_features,\n",
    "                         training_set_size,\n",
    "                         test_set_size,\n",
    "                         batch_size // 2)\n",
    "data_owner_1 = DataOwner('data-owner-1',\n",
    "                         num_features,\n",
    "                         training_set_size,\n",
    "                         test_set_size,\n",
    "                         batch_size // 2)\n",
    "\n",
    "tfe.set_protocol(tfe.protocol.Pond(\n",
    "    tfe.get_config().get_player(data_owner_0.player_name),\n",
    "    tfe.get_config().get_player(data_owner_1.player_name)\n",
    "))\n",
    "\n",
    "x_train_0, y_train_0 = data_owner_0.provide_training_data()\n",
    "x_train_1, y_train_1 = data_owner_1.provide_training_data()\n",
    "\n",
    "x_test_0, y_test_0 = data_owner_0.provide_testing_data()\n",
    "x_test_1, y_test_1 = data_owner_1.provide_testing_data()\n",
    "\n",
    "x_train = tfe.concat([x_train_0, x_train_1], axis=0)\n",
    "y_train = tfe.concat([y_train_0, y_train_1], axis=0)\n",
    "\n",
    "model = LogisticRegression(num_features)\n",
    "reveal_weights_op = model_owner.receive_weights(model.weights)\n",
    "\n",
    "with tfe.Session() as sess:\n",
    "  sess.run([tfe.global_variables_initializer(),\n",
    "            data_owner_0.initializer,\n",
    "            data_owner_1.initializer],\n",
    "           tag='init')\n",
    "\n",
    "  model.fit(sess, x_train, y_train, num_batches)\n",
    "  # TODO(Morten)\n",
    "  # each evaluation results in nodes for a forward pass being added to the graph;\n",
    "  # maybe there's some way to avoid this, even if it means only if the shapes match\n",
    "  model.evaluate(sess, x_test_0, y_test_0, data_owner_0)\n",
    "  model.evaluate(sess, x_test_1, y_test_1, data_owner_1)\n",
    "\n",
    "  sess.run(reveal_weights_op, tag='reveal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on prediction-client-0: [[0.49794238683127573]]\r\n"
     ]
    }
   ],
   "source": [
    "num_features = 10\n",
    "\n",
    "model = LogisticRegression(num_features)\n",
    "prediction_client_0 = PredictionClient('prediction-client-0', num_features // 2)\n",
    "prediction_client_1 = PredictionClient('prediction-client-1', num_features // 2)\n",
    "result_receiver = prediction_client_0\n",
    "\n",
    "x_0 = prediction_client_0.provide_input()\n",
    "x_1 = prediction_client_1.provide_input()\n",
    "x = tfe.concat([x_0, x_1], axis=1)\n",
    "\n",
    "y = model.forward(x)\n",
    "\n",
    "\n",
    "reveal_output = result_receiver.receive_output(y)\n",
    "\n",
    "with tfe.Session() as sess:\n",
    "  sess.run(tfe.global_variables_initializer(), tag='init')\n",
    "\n",
    "  sess.run(reveal_output, tag='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
