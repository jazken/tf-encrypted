{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ReLU\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "60000\n",
      "[9 0 0 ... 3 0 5]\n",
      "(10000, 28, 28)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#data exploration\n",
    "\n",
    "print(train_images.shape)\n",
    "print(len(train_labels))\n",
    "print(train_labels)\n",
    "print(test_images.shape)\n",
    "print(len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdDklEQVR4nO3dfXBc5ZXn8e+RLMm2LL9hYww4MRCTYJLFZB0gMJUhYSZAKjWGSUhBzTJODTVmd2EnTPEHhJ2tsDXFFpUNsKnJwI4JbJwqCOsJMDAMFV4cEkIyvBjj4LclNtjBxsavYBvbsqXus3/01dCydM+9UrfUfc3vQ3WpdU8/fR+3pMO9zz33eczdEREpqpZGd0BEpBZKYiJSaEpiIlJoSmIiUmhKYiJSaGNGc2ft1uFj6RzNXYp8pHRzgCN+2Gp5j4u/2Om795RyvfbV1w8/5e6X1LK/WtWUxMzsEuD7QCvwQ3e/PXr9WDo51y6qZZciEnjJl9X8Hrv3lHj5qY/lem3rzPXTat5hjYZ9OmlmrcDfA5cCc4GrzGxuvTomIo3hQDnnf1nMbJaZPWdm68xsjZl9K9l+q5m9Y2Yrk8dXqtp828w2mNkbZnZx1j5qORI7B9jg7m8lO34IWACsreE9RaTBHKfH851O5tAL3OjuK8ysC3jVzJ5JYne5+/eqX5wcCF0JnAmcCDxrZqe7p3eoloH9k4DNVd9vSbb1Y2aLzGy5mS3v4XANuxOR0VKvIzF33+buK5Ln+4F1DJInqiwAHnL3w+6+EdhA5YApVS1JbLDBwwH3MLn7Ynef7+7z2+ioYXciMhocp+T5HsC0voOU5LEo7X3NbDZwNvBSsul6M3vdzO43synJtlwHR9VqSWJbgFlV358MbK3h/USkSZTxXA9gV99BSvJYPNj7mdkE4GHgBnffB9wDnAbMA7YBd/S9dJDm4Q3etSSxV4A5ZnaKmbVTOY99vIb3E5Em4EAJz/XIw8zaqCSwB9z9EQB33+7uJXcvA/fy4SnjkA+Ohp3E3L0XuB54isp57lJ3XzPc9xOR5jGEI7GQmRlwH7DO3e+s2j6z6mWXA6uT548DV5pZh5mdAswBXo72UVOdmLs/CTxZy3uISHNxoKd+U3RdAFwNrDKzlcm2W6iUZM1LdrcJuBbA3deY2VIqVQ69wHXRlUkY5Yp9EWl+PoRTxcz3cn+Bwce5Ug9+3P024La8+1ASE5H+HEoFmitVSUxE+qlU7BeHkpiIHMUoDXoG2JyUxESkn8rAvpKYiBRUpU5MSUxECqysIzERKSodiYlIoTlGqUAz1yuJicgAOp0UkcJyjCPe2uhu5KYkJiL9VIpddTopIgWmgX1pHpbxy1jjbAWtx00N4+9dfHpqbOKDL9a076x/m41pS415z5Ha9l2rrJ9LpH4zTKS8vVFyHYmJSIGVdSQmIkVVGdgvTmooTk9FZFRoYF9ECq+kOjERKSpV7ItI4ZV1dVJEiqpyA7iSmDQJa41vH/He3jDeMm9uGF937YS4/aH0WNuBcHV6xhyKJ0lue3p5GK+pFiyrBi3jc8XiJFBL32xM8Gcb/zhzcYwe3XYkIkXljopdRaTITMWuIlJcjo7ERKTgNLAvIoXlmCZFFJHiqizZVpzUUJyeisgo0eK50kTCmiKy68Q2Xzw5jP/Z538Vxn+989TU2O87Tgjb+rgwzJg/+nwYP/3ud1JjvZvejt88Y86urM8tS+uUKenBUilsW9q3Lz1Yh6nGnI9Qxb6ZbQL2AyWg193n16NTItJYH7UjsS+6+646vI+INAF3++gciYnIsacysP/Rue3IgafNzIF/cPfFR7/AzBYBiwDGMr7G3YnIyCvWHPu19vQCd/8scClwnZl94egXuPtid5/v7vPb6KhxdyIy0ioD+5brkcXMZpnZc2a2zszWmNm3ku1TzewZM1uffJ1S1ebbZrbBzN4ws4uz9lFTEnP3rcnXHcCjQDwtgYgUQomWXI8ceoEb3f0M4DwqBztzgZuBZe4+B1iWfE8SuxI4E7gEuNvMwnPbYScxM+s0s66+58CXgdXDfT8RaQ59Ffv1OBJz923uviJ5vh9YB5wELACWJC9bAlyWPF8APOTuh919I7CBjIOjWsbEZgCPWmXepTHAg+7+sxreT0ZAubu7pvZHzv4gjH99Ujyn19iWntTYL1vi+cLe+fmsMF76d3Hffn9nV2qs/Nr5YdvjVse1WhNf2xbGd33hpDC+89+nF3TNyFiOc8qzb6bGbE99rtUNYaGQaWZW/UuweLCxcQAzmw2cDbwEzHD3bVBJdGZ2fPKyk4DqT2BLsi3VsP/F7v4WcNZw24tIc3KHnnLuJLYrT32omU0AHgZucPd9lj7p5GCBsIRXJRYi0k/ldLJ+VyfNrI1KAnvA3R9JNm83s5nJUdhMYEeyfQtQfQh+MrA1ev/iXEcVkVFTSu6fzHpkscoh133AOne/syr0OLAweb4QeKxq+5Vm1mFmpwBzgJejfehITET66SuxqJMLgKuBVWa2Mtl2C3A7sNTMrgHeBq4AcPc1ZrYUWEvlyuZ17h4OUCqJichR6nc66e4vMPg4F8BFKW1uA27Luw8lMREZQHPsy+iKlhfLmFLmg2+cF8b/fO4vwvibPdPD+Mnte1JjV5z4atiW/xDHf/DGH4bxA29NSo21dMafy7vnxUci7yyI/93eE0/VM2VF+p9ey8LtYdt9R9KnNyotq/2umMrVyY/OvZMicozR9NQiUng6nRSRwqrz1ckRpyQmIgNoUkQRKSx3o1dJTESKTKeTIlJYGhOToYvqvEbYeTeFt6XxxQlra3r/k4IJCA54e9j2/VJnGP/O3H8J4ztPT5+KJ2tx2B+uj6fq+SCoQQNo7Y1/puf9xWupsa9NfSVs+92HP5Maa/EDYdu8lMREpLBUJyYihac6MREpLHfozT8pYsMpiYnIADqdFJHC0piYiBSeK4mJSJFpYF+GJmPOr5G0/oPjw/juiRPC+Lu9k8P4ca3py6p1tRwK285u2xXGd5bS68AAWtvSl4Q74vF8Wf/9zH8O491ntIXxNouXfDt/bPraF1es/fOwbSdvhfFauWtMTEQKzSjp6qSIFJnGxESksHTvpIgUmzd0mHbIlMREZABdnRSRwnIN7ItI0el0Ugpjekd6HRfAWOsJ4+0Wr6+4tWdKamz9oU+GbX+3L65hu2TGmjDeE9SCtQbznEF2ndeJbe+F8W6P68iiT/WCGXEd2MowWh9FujqZecxoZveb2Q4zW121baqZPWNm65Ov6b+pIlIo7pUklufRDPKc+P4IuOSobTcDy9x9DrAs+V5EjhFlt1yPZpCZxNz9eeDotegXAEuS50uAy+rcLxFpIPd8j2Yw3DGxGe6+DcDdt5lZ6uCFmS0CFgGMZfwwdycio8UxygW6OjniPXX3xe4+393nt9Ex0rsTkTrwnI9mMNwktt3MZgIkX3fUr0si0lDH4MD+YB4HFibPFwKP1ac7ItIUCnQoljkmZmY/AS4EppnZFuA7wO3AUjO7BngbuGIkO3nMy1h30lrjua+8N71Wq3VKXP3yh5NXhfGdpYlh/P1SPM45ufVgamx/79iw7Z5D8Xt/qmNbGF9xcHZqbHp7XOcV9Rtg05FpYXxOx7th/LvbL0qNzRp79HW0/nov+kJqzF/617BtXs1ylJVHZhJz96tSQuk/BREpLAfK5fokMTO7H/gqsMPdP51suxX4S2Bn8rJb3P3JJPZt4BqgBPyVuz+VtY/iXIIQkdHhgFu+R7YfMbDOFOAud5+XPPoS2FzgSuDMpM3dZhafhqAkJiKDqFedWEqdaZoFwEPuftjdNwIbgHOyGimJichA+Qf2p5nZ8qrHopx7uN7MXk9ua+wbuD0J2Fz1mi3JtpBuABeRowypfGKXu88f4g7uAf6WShr8W+AO4C9g0EnMMo/3dCQmIgONYImFu29395K7l4F7+fCUcQswq+qlJwPpy0IldCTWDDIGF2xM/GOKSiw2X3NG2PZL4+OlyX7THR/NTx+zP4xH0+HM7Ngbtu2a0R3Gs8o7po5Jn2Zof2lc2HZ8y+EwnvXv/mx7vNzcXz/72dRY16d3h20ntgXHHvW4qOjgdbo6ORgzm9l32yJwOdA3Q87jwINmdidwIjAHeDnr/ZTERGQQdSuxGKzO9EIzm0flWG4TcC2Au68xs6XAWqAXuM7d44ndUBITkcHUqRo/pc70vuD1twG3DWUfSmIiMlCT3FKUh5KYiPTXV+xaEEpiIjJAs0x4mIeSmIgMNIJXJ+tNSUxEBjAdiclQWFt7GC93x/VSkWmrjoTxXaV4abHJLfGUNO0ZS5sdCerEzp+6MWy7M6OWa8WhU8J4V+uh1Nj0lrjOa1ZbXKu1qntWGH/ywCfC+DVffTY19pPFfxy2bf/Zb1Jj5vHPK5cmmissDyUxETlK7hkqmoKSmIgMpCMxESm0cqM7kJ+SmIj0pzoxESk6XZ0UkWIrUBLTfGIiUmjFOhILljazMXG9k7Vm5OuWOF7uDuaXKmfOFhLynriWqxbf/4cfhPHNvZPD+Ls9cTxrabNSMKXLi4cmhW3HtvSE8elj9oXxfeW4ziyyvxwvJxfNkwbZfb/puPWpsUf2/lHYdjTodFJEisvRbUciUnA6EhORItPppIgUm5KYiBSakpiIFJW5TidFpOh0dXJ4allfMavWyuOynYY6tOCcML75srgO7c/OTl+a793errDtawdnh/FJwZxcAJ0Z6zN2e3r93tYjU1JjkF1rFa0rCXB8UEdW8rgu8J2euG9ZsurntvQGa2L+STzX2eQfD6tLQ1KkI7HMin0zu9/MdpjZ6qptt5rZO2a2Mnl8ZWS7KSKjagRXAK+3PLcd/Qi4ZJDtd7n7vOTxZH27JSIN4x+Oi2U9mkFmEnP354E9o9AXEWkWx9iRWJrrzez15HQzdQDBzBaZ2XIzW95DPH4iIs3ByvkezWC4Sewe4DRgHrANuCPthe6+2N3nu/v8NjqGuTsRkcENK4m5+3Z3L7l7GbgXiC+viUixHOunk2Y2s+rby4HVaa8VkYIp2MB+Zp2Ymf0EuBCYZmZbgO8AF5rZPCq5eBNwbT06E9WB1WrMzBPCeM8pM8L4njPGp8YOnhAXBs77yrow/s0Z/yeM7yxNDONtlv65be45Lmx79vhNYfzne+eG8V1jJoTxqM7s/M70ObUA3i+nf+YAJ455L4zftOHrqbEZ4+NarB9+PL7g3uPxgNAbPfHQyd5y+nxkfzX3ubDto0wP43XRJAkqj8wk5u5XDbL5vhHoi4g0i2MpiYnIR4vRPFce81ASE5H+mmi8Kw8tFCIiA9Xp6mTKbYtTzewZM1uffJ1SFfu2mW0wszfM7OI8XVUSE5GB6ldi8SMG3rZ4M7DM3ecAy5LvMbO5wJXAmUmbu80sXpEFJTERGUS9SixSbltcACxJni8BLqva/pC7H3b3jcAGctSgNtWY2OFLPxfGj/+vb6XG5k3cEradO+6FMN5djpd8i6aFWXvopLDtwXJ7GF9/JC7/2Nsblxq0BqOwO47EU/HcsTFeHmzZOf87jP/N1sHmBvhQy7j03/Tdpbg842sT4iXZIP6ZXfux51Njp7bvCNs+cWBmGN+aMVXPjLa9YXx2287U2J92/S5sewyUWMxw920A7r7NzI5Ptp8EvFj1ui3JtlBTJTERaQI+pKuT08xsedX3i9198TD3PFjBZWY6VRITkYHyH4ntcvf5Q3z37WY2MzkKmwn0HRZvAWZVve5kYGvWm2lMTEQGGOHbjh4HFibPFwKPVW2/0sw6zOwUYA6QPm1xQkdiIjJQncbEUm5bvB1YambXAG8DVwC4+xozWwqsBXqB69w9npsdJTEROVodZ6hIuW0R4KKU198G3DaUfSiJiUg/RrEq9pXERGQAJbE0Fi/Ldu7/eCVsflHXmtTYQY+nPsmqA8uq+4lMGhMvz3W4J/6Yd/TEU+1kOb3j3dTY5RNXhm2f/8G5YfwPuv9LGH/zS/E0QssOpRdc7+yN/91XbvxSGF/x9qwwft7sjamxz3S9E7bNqs3rau0O49H0SAAHyum/ry92x/Vzo0JJTEQKTUlMRAqrYLNYKImJyEBKYiJSZJoUUUQKTaeTIlJcTbQcWx5KYiIykJLY4HqO72Tr1elznN066e/C9g/uOS81Nmvs0fOu9ffx9l1h/Kxxvw/jka6WuGbokxPjmqEnDpwcxn/x/qfC+My291Njvzp4Wtj2oVv/Zxj/5l/fGMY//+R/DOP7ZqfPMdDbGf+lTDxrdxj/m7P/JYy3W/ptd++X4jqwqR0Hwvjk1rg2MEtU19jVkr7MHUDrJz+RGrNN8bx5eahiX0QKz8rFyWJKYiLSn8bERKTodDopIsWmJCYiRaYjMREpNiUxESmsoa121HCjmsRaemD89vRP54l988L2p45LX6tvV0+8vuJTH3wmjJ887r0wPqk1vXbnE8F8XgAruyeH8Z/tPDOMnzguXn9xe8+k1Njuns6w7cFgXiuA++66M4zfsT1et/LyqStSY2e1x3Vg75fjdWzWZqzXub88NjXW7fH8cnsz6si6gt8HgB6P/7RaPf3vYHJLXIO27zPHpcZK22v/ky5anVjmakdmNsvMnjOzdWa2xsy+lWyfambPmNn65OvwZxUUkebinu/RBPIs2dYL3OjuZwDnAdeZ2VzgZmCZu88BliXfi8gxYISXbKurzCTm7tvcfUXyfD+wjsrS4guAJcnLlgCXjVQnRWQU+RAeTWBIJ9BmNhs4G3gJmOHu26CS6Mzs+JQ2i4BFAO2dOuMUKYIiDeznXgHczCYADwM3uHs80lzF3Re7+3x3nz+mIx5kFpHmYOV8j2aQK4mZWRuVBPaAuz+SbN5uZjOT+Exgx8h0UURGlVOogf3M00kzM+A+YJ27V19vfxxYSGVJ8oXAY1nv1XqkTNfmw6nxslvY/ue70qekmTF2f9h2XtfmMP7Gwfhy/apDJ6bGVoz5WNh2XGtPGJ/UHk/l0zkm/TMDmNaW/m8/pSP+f0s0XQ3AK93xv+0/Tf9FGH+7N30I4Z8PnB62XXsw/TMHmJKxVN6qfentD/a2h20Pl+I/je7euGRnUkf8M/3c1PSpn95gZth251nB9Ea/Dpvm1iyD9nnkGRO7ALgaWGVmfYsY3kIleS01s2uAt4ErRqaLIjLqjqUk5u4vUKl/G8xF9e2OiDRa0YpddduRiPTnrkkRRaTgipPDlMREZCCdTopIcTmg00kRKbTi5LBRTmIfHKLll6+lhv/x6QvC5v9twT+mxn6ZsazZE+/GdT37jsRT0kwfn76E18SgTgtgalu8/NekjHqnsRYv+fZeb/qdEIdb4ilnSqkXnivePZw+zQ/Ar8tzwnhPuTU1djiIQXZ93Z4j08L4ieP2psb296ZP0wOwaf/UML5r74Qw3j0+/tN6oZS+lN4lJ6wJ247bkf4za4l/VXLT6aSIFFo9r06a2SZgP1ACet19vplNBf4vMBvYBHzD3eNJ/VLkvndSRD4iRmYWiy+6+zx3n598X7epvJTERKSfSrGr53rUoG5TeSmJichA5ZwPmGZmy6seiwZ5NweeNrNXq+L9pvICBp3KKw+NiYnIAEM4ytpVdYqY5gJ335rMOfiMmf2/2nrXn47ERKS/Oo+JufvW5OsO4FHgHOo4lZeSmIgcpXLvZJ5HFjPrNLOuvufAl4HVfDiVF+ScyitNU51OnnrTv4bxu1//enrb//xG2PbSE1aH8RX74nmz3g7qhn4bzDUG0NYST4E5vu1IGB+bUS/V3po+J1hLxv8uyxl1Yp2tcd+y5jqb2pFeI9fVGs+51VLj1KGtwb/95b2zw7Yzxse1f5+YuCuM93p8fPD5SW+mxu7feH7Ydsbf/SY1tsnjmsTc6jfh4Qzg0cq0hIwBHnT3n5nZK9RpKq+mSmIi0gTquHiuu78FnDXI9t3UaSovJTERGahJpp7OQ0lMRAYqTg5TEhORgazcJEsZ5aAkJiL9OX2FrIWgJCYi/Rg131I0qpTERGQgJbFASzCHVDleA3HSAy+mxnY/EO/2p1+7OIyfe8srYfyrs3+bGvtU+/awbVvGsfnYjOvZnS1xLVd38AuXVc38wqFZYbyU8Q4/f++MMP5+z7jU2PaDE8O2bUH9Wx7ROqaHeuN51vYeiucba22J/8i7fxHPdbZxbfr8d5OejH8XR4WSmIgUlsbERKTodHVSRArMdTopIgXmKImJSMEV52xSSUxEBlKdmIgU27GUxMxsFvBj4AQqB5mL3f37ZnYr8JfAzuSlt7j7k5l7zKgFGymdD78Uxlc/HLdfzSmpMfvcn4RtD52QXisF0LE7npNr/8fj9hPfTJ9DquVwvBBh+bfrwni2D2pouy+MxrOo1aY9Iz695j38ruZ3aBh3KBXnfDLPkVgvcKO7r0hmaHzVzJ5JYne5+/dGrnsi0hDH0pFYshJJ36ok+81sHXDSSHdMRBqoQElsSHPsm9ls4Gyg79zsejN73czuN7MpKW0W9S3n1EN82iQiTcCBsud7NIHcSczMJgAPAze4+z7gHuA0YB6VI7U7Bmvn7ovdfb67z2+jow5dFpGR5eDlfI8mkOvqpJm1UUlgD7j7IwDuvr0qfi/wxIj0UERGl1Oogf3MIzGrLFNyH7DO3e+s2j6z6mWXU1mGSUSOBe75Hk0gz5HYBcDVwCozW5lsuwW4yszmUcnbm4BrR6SHBeCvrArj8aQu2Samr9CVqTj/P5Wm0iQJKo88VydfgEEXJ8yuCRORAmqeo6w8VLEvIv05oKl4RKTQdCQmIsV17N12JCIfJQ7eJDVgeSiJichATVKNn4eSmIgMpDExESksd12dFJGC05GYiBSX46XGTF46HEpiItJf31Q8BaEkJiIDFajEYkiTIorIsc8BL3uuRx5mdomZvWFmG8zs5nr3V0lMRPrz+k2KaGatwN8DlwJzqcx+M7ee3dXppIgMUMeB/XOADe7+FoCZPQQsANbWawejmsT2896uZ/2nv6/aNA3YNZp9GIJm7Vuz9gvUt+GqZ98+Xusb7Oe9p571n07L+fKxZra86vvF7r646vuTgM1V328Bzq21j9VGNYm5e7/l/MxsubvPH80+5NWsfWvWfoH6NlzN1jd3v6SObzfYXIR1vfSpMTERGUlbgFlV358MbK3nDpTERGQkvQLMMbNTzKwduBJ4vJ47aPTA/uLslzRMs/atWfsF6ttwNXPfauLuvWZ2PfAU0Arc7+5r6rkP8wLdIyUicjSdTopIoSmJiUihNSSJjfRtCLUws01mtsrMVh5V/9KIvtxvZjvMbHXVtqlm9oyZrU++Tmmivt1qZu8kn91KM/tKg/o2y8yeM7N1ZrbGzL6VbG/oZxf0qyk+t6Ia9TGx5DaE3wF/TOXy6yvAVe5etwreWpjZJmC+uze8MNLMvgB8APzY3T+dbPsusMfdb0/+BzDF3W9qkr7dCnzg7t8b7f4c1beZwEx3X2FmXcCrwGXAN2ngZxf06xs0wedWVI04Evu32xDc/QjQdxuCHMXdnwf2HLV5AbAkeb6Eyh/BqEvpW1Nw923uviJ5vh9YR6VyvKGfXdAvqUEjkthgtyE00w/SgafN7FUzW9Tozgxihrtvg8ofBXB8g/tztOvN7PXkdLMhp7rVzGw2cDbwEk302R3VL2iyz61IGpHERvw2hBpd4O6fpXLX/XXJaZPkcw9wGjAP2Abc0cjOmNkE4GHgBnff18i+VBukX031uRVNI5LYiN+GUAt335p83QE8SuX0t5lsT8ZW+sZYdjS4P//G3be7e8krixbeSwM/OzNro5IoHnD3R5LNDf/sButXM31uRdSIJDbityEMl5l1JgOumFkn8GVgddxq1D0OLEyeLwQea2Bf+ulLEInLadBnZ2YG3Aesc/c7q0IN/ezS+tUsn1tRNaRiP7mE/L/48DaE20a9E4Mws1OpHH1B5ZasBxvZNzP7CXAhlalatgPfAf4JWAp8DHgbuMLdR32APaVvF1I5JXJgE3Bt3xjUKPftD4BfAauAvpn7bqEy/tSwzy7o11U0wedWVLrtSEQKTRX7IlJoSmIiUmhKYiJSaEpiIlJoSmIiUmhKYiJSaEpiIlJo/x/RvxJh5ClQ5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.4963 - acc: 0.8258\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3750 - acc: 0.8643\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3384 - acc: 0.8773\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3133 - acc: 0.8844\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2962 - acc: 0.8914\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2801 - acc: 0.8968\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2692 - acc: 0.8994\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2578 - acc: 0.9042\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2491 - acc: 0.9071\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2407 - acc: 0.9092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18beb2372b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.3256 - acc: 0.8867\n",
      "\n",
      "Test accuracy: 0.8867\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Secure Model Training with Syft Keras\n",
    "\n",
    "In this notebook, we want to benchmark the additional time required to train an encrypted model securely using the SecureNN protocol over a normal tensorflow training.\n",
    "\n",
    "To secure and train this model, we will need three TFEWorkers (servers). This is because TF Encrypted under the hood uses an encryption technique called multi-party computation (MPC). The idea is to split the model weights and input data into shares, then send a share of each value to the different servers. The key property is that if you look at the share on one server, it reveals nothing about the original value (input data or model weights).\n",
    "\n",
    "We'll define a Syft Keras model like we did in the previous notebook. However, there is a trick: before instantiating this model, we'll run hook = sy.KerasHook(tf.keras). This will add three important new methods to the Keras Sequential class:\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "share: will secure your model via secret sharing; by default, it will use the SecureNN protocol from TF Encrypted to secret share your model between each of the three TFEWorkers. Most importantly, this will add the capability of providing predictions on encrypted data.\n",
    "    </li>\n",
    "    <li>\n",
    "serve: this function will launch a serving queue, so that the TFEWorkers can accept prediction requests on the secured model from external clients.\n",
    "    </li>\n",
    "    <li>\n",
    "shutdown_workers: once you are done providing private predictions, you can shut down your model by running this function. It will direct you to shutdown the server processes manually if you've opted to manually manage each worker.\n",
    "If you want to learn more about MPC, you can read this excellent blog.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.2.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "hook = sy.KerasHook(tf.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using private tensorflow\n",
    "##helper functions\n",
    "\n",
    "def encode_image(value):\n",
    "    \"\"\"Encode images into a tf.train.Feature for a TFRecord.\"\"\"\n",
    "    bytes_list = tf.train.BytesList(value=[value.tostring()])\n",
    "    return tf.train.Feature(bytes_list=bytes_list)\n",
    "\n",
    "\n",
    "def decode_image(value):\n",
    "    \"\"\"Decode the image from a tf.train.Feature in a TFRecord.\"\"\"\n",
    "    image = tf.decode_raw(value, tf.uint8)\n",
    "    image.set_shape((28 * 28))\n",
    "    return image\n",
    "\n",
    "\n",
    "def encode_label(value):\n",
    "    \"\"\"Encode a label into a tf.train.Feature for a TFRecord.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def decode_label(value):\n",
    "    \"\"\"Decode the label from a tf.train.Feature in a TFRecord.\"\"\"\n",
    "    return tf.cast(value, tf.int32)\n",
    "\n",
    "\n",
    "def encode(image, label):\n",
    "    \"\"\"Encode an instance as a tf.train.Example for a TFRecord.\"\"\"\n",
    "    feature_dict = {'image': encode_image(image), 'label': encode_label(label)}\n",
    "    features = tf.train.Features(feature=feature_dict)\n",
    "    return tf.train.Example(features=features)\n",
    "\n",
    "\n",
    "def decode(serialized_example):\n",
    "    \"\"\"Decode an instance from a tf.train.Example in a TFRecord.\"\"\"\n",
    "    features = tf.parse_single_example(serialized_example, features={\n",
    "      'image': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "    image = decode_image(features['image'])\n",
    "    label = decode_label(features['label'])\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def normalize(image, label):\n",
    "    \"\"\"Standardization of MNIST images.\"\"\"\n",
    "    x = tf.cast(image, tf.float32) / 255.\n",
    "    image = (x - 0.1307) / 0.3081  # image = (x - mean) / std\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def get_data_from_tfrecord(filename, batch_size: int):\n",
    "    \"\"\"Construct a TFRecordDataset iterator.\"\"\"\n",
    "    return tf.data.TFRecordDataset([filename]) \\\n",
    "                .map(decode) \\\n",
    "                .map(normalize) \\\n",
    "                .repeat() \\\n",
    "                .batch(batch_size) \\\n",
    "                .make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_training_data(images, labels, filename):\n",
    "    \"\"\"Convert Keras MNIST data into TFRecords.\"\"\"\n",
    "    assert images.shape[0] == labels.shape[0]\n",
    "    num_examples = images.shape[0]\n",
    "\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "\n",
    "        for index in range(num_examples):\n",
    "\n",
    "            image = images[index]\n",
    "            label = labels[index]\n",
    "            example = encode(image, label)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# used on top for normal local training (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "data_dir = os.path.expanduser(\"./data/\")\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "save_training_data(train_images, train_labels, os.path.join(data_dir, \"train.tfrecord\"))\n",
    "save_training_data(test_images, test_labels, os.path.join(data_dir, \"test.tfrecord\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional imports for tf encrypted\n",
    "import sys\n",
    "import logging\n",
    "import tf_encrypted as tfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = True\n",
    "\n",
    "alice = sy.TFEWorker(host='localhost:4000', auto_managed=AUTO)\n",
    "bob = sy.TFEWorker(host='localhost:4001', auto_managed=AUTO)\n",
    "carol = sy.TFEWorker(host='localhost:4002', auto_managed=AUTO)\n",
    "\n",
    "cluster = sy.TFECluster(alice, bob, carol)\n",
    "cluster.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model owner \n",
    "\n",
    "class ModelOwner():\n",
    "    \"\"\"Contains code meant to be executed by the model owner.\n",
    "    Args:\n",
    "    player_name: `str`, name of the `tfe.player.Player`\n",
    "                 representing the model owner.\n",
    "    local_data_file: filepath to MNIST data.\n",
    "    \"\"\"\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_CLASSES = 10\n",
    "    EPOCHS = 1\n",
    "\n",
    "    ITERATIONS = 60000 // BATCH_SIZE\n",
    "\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "    FLATTENED_DIM = IMG_ROWS * IMG_COLS\n",
    "\n",
    "    def __init__(self, player_name, local_data_file):\n",
    "        self.player_name = player_name\n",
    "        self.local_data_file = local_data_file\n",
    "\n",
    "    def _build_data_pipeline(self):\n",
    "        \"\"\"Build a reproducible tf.data iterator.\"\"\"\n",
    "\n",
    "        def normalize(image, label):\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "            return image, label\n",
    "\n",
    "        def flatten(image, label):\n",
    "            image = tf.reshape(image, shape=[self.FLATTENED_DIM])\n",
    "            return image, label\n",
    "\n",
    "            dataset = tf.data.TFRecordDataset([self.local_data_file])\n",
    "            dataset = dataset.map(decode)\n",
    "            dataset = dataset.map(normalize)\n",
    "            dataset = dataset.map(flatten)\n",
    "            dataset = dataset.repeat()\n",
    "            dataset = dataset.batch(self.BATCH_SIZE)\n",
    "\n",
    "            iterator = dataset.make_one_shot_iterator()\n",
    "            return iterator\n",
    "\n",
    "    def _build_training_graph(self, training_data):\n",
    "        \"\"\"Build a graph for plaintext model training.\"\"\"\n",
    "\n",
    "        model = keras.Sequential()\n",
    "        #update to 128 nodes compared to 512 to follow above tensorflow/keras demo\n",
    "        model.add(keras.layers.Dense(128, input_shape=[self.FLATTENED_DIM,]))\n",
    "        model.add(keras.layers.Activation('relu'))\n",
    "        model.add(keras.layers.Dense(self.NUM_CLASSES, activation=None))\n",
    "\n",
    "        # optimizer and data pipeline\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "\n",
    "        def loss(model, inputs, targets):\n",
    "            logits = model(inputs)\n",
    "            per_element_loss = tf.losses.sparse_softmax_cross_entropy(labels=targets, logits=logits)\n",
    "            return tf.reduce_mean(per_element_loss)\n",
    "\n",
    "        def grad(model, inputs, targets):\n",
    "            loss_value = loss(model, inputs, targets)\n",
    "            return loss_value, tf.gradients(loss_value, model.trainable_variables)\n",
    "\n",
    "        def loop_body(i):\n",
    "            x, y = training_data.get_next()\n",
    "            _, grads = grad(model, x, y)\n",
    "            update_op = optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            with tf.control_dependencies([update_op]):\n",
    "                return i + 1\n",
    "\n",
    "            loop = tf.while_loop(lambda i: i < self.ITERATIONS * self.EPOCHS,loop_body, loop_vars=(0,))\n",
    "\n",
    "            with tf.control_dependencies([loop]):\n",
    "                print_op = tf.print(\"Training complete\")\n",
    "            with tf.control_dependencies([print_op]):\n",
    "                return [tf.identity(x) for x in model.trainable_variables]\n",
    "\n",
    "    @tfe.local_computation\n",
    "    def provide_weights(self):\n",
    "        with tf.name_scope('loading'):\n",
    "            training_data = self._build_data_pipeline()\n",
    "\n",
    "        with tf.name_scope('training'):\n",
    "            parameters = self._build_training_graph(training_data)\n",
    "\n",
    "        return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class ModelTrainer():\n",
    "    \"\"\"Contains code meant to be executed by a model training Player.\"\"\"\n",
    "\n",
    "    BATCH_SIZE = 256\n",
    "    ITERATIONS = 60000 // BATCH_SIZE\n",
    "    EPOCHS = 3\n",
    "    LEARNING_RATE = 3e-3\n",
    "    IN_N = 28 * 28\n",
    "    HIDDEN_N = 128\n",
    "    OUT_N = 10\n",
    "\n",
    "    def cond(self,\n",
    "            i: int,\n",
    "            max_iter: tf.Tensor,\n",
    "            nb_epochs: tf.Tensor,\n",
    "            avg_loss: tf.Tensor):\n",
    "        \"\"\"Check if training termination condition has been met.\"\"\"\n",
    "        is_end_epoch = tf.equal(i % max_iter, 0)\n",
    "        to_continue = tf.cast(i < max_iter * nb_epochs, tf.bool)\n",
    "\n",
    "        def true_fn() -> tf.Tensor:\n",
    "            to_continue = tf.print(\"avg_loss: \", avg_loss)\n",
    "            return to_continue\n",
    "\n",
    "        def false_fn() -> tf.Tensor:\n",
    "            return to_continue\n",
    "\n",
    "        return tf.cond(is_end_epoch, true_fn, false_fn)\n",
    "\n",
    "    def build_training_graph(self, training_data) -> List[tf.Tensor]:\n",
    "        \"\"\"Build a graph for plaintext model training.\n",
    "\n",
    "        Returns a list of the trained model's parameters.\n",
    "        \"\"\"\n",
    "        j = self.IN_N\n",
    "        k = self.HIDDEN_N\n",
    "        m = self.OUT_N\n",
    "\n",
    "        # model parameters and initial values\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(k, input_shape=[j,]))\n",
    "        model.add(keras.layers.Activation('relu'))\n",
    "        model.add(keras.layers.Dense(k))\n",
    "        model.add(keras.layers.Activation('relu'))\n",
    "        model.add(keras.layers.Dense(m))\n",
    "\n",
    "        # optimizer and data pipeline\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.LEARNING_RATE)\n",
    "\n",
    "        def loss(model, inputs, targets):\n",
    "            logits = model(inputs)\n",
    "            per_element_loss = tf.losses.sparse_softmax_cross_entropy(labels=targets, logits=logits)\n",
    "            return tf.reduce_mean(per_element_loss)\n",
    "\n",
    "        def grad(model, inputs, targets):\n",
    "            loss_value = loss(model, inputs, targets)\n",
    "            return loss_value, tf.gradients(loss_value, model.trainable_variables)\n",
    "\n",
    "        # training loop\n",
    "        def loop_body(i, max_iter, nb_epochs, avg_loss):\n",
    "            x, y = training_data.get_next()\n",
    "            loss, grads = grad(model, x, y)\n",
    "            update_op = optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "            is_end_epoch = tf.equal(i % max_iter, 0)\n",
    "\n",
    "            def true_fn() -> tf.Tensor:\n",
    "                return loss\n",
    "\n",
    "            def false_fn() -> tf.Tensor:\n",
    "                prev_loss = tf.cast(i - 1, tf.float32) * avg_loss\n",
    "                return (prev_loss + loss) / tf.cast(i, tf.float32)\n",
    "\n",
    "            with tf.control_dependencies([update_op]):\n",
    "                terminal_cond = tf.cond(is_end_epoch, true_fn, false_fn)\n",
    "                return i + 1, max_iter, nb_epochs, terminal_cond\n",
    "\n",
    "        loop, _, _, _ = tf.while_loop(self.cond, loop_body, [0, self.ITERATIONS, self.EPOCHS, 0.])\n",
    "\n",
    "        # return model parameters after training\n",
    "        loop = tf.print(\"Training complete\", loop)\n",
    "\n",
    "        with tf.control_dependencies([loop]):\n",
    "            return [tf.identity(x) for x in model.trainable_variables]\n",
    "\n",
    "    def provide_input(self) -> List[tf.Tensor]:\n",
    "        with tf.name_scope('loading'):\n",
    "            training_data = get_data_from_tfrecord(\"./data/train.tfrecord\", self.BATCH_SIZE, flattened=True)\n",
    "\n",
    "        with tf.name_scope('training'):\n",
    "            parameters = self.build_training_graph(training_data)\n",
    "\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionClient():\n",
    "    \"\"\"\n",
    "    Contains code meant to be executed by a prediction client.\n",
    "    Args:\n",
    "    player_name: `str`, name of the `tfe.player.Player`\n",
    "                 representing the data owner\n",
    "    build_update_step: `Callable`, the function used to construct\n",
    "                       a local federated learning update.\n",
    "    \"\"\"\n",
    "\n",
    "    BATCH_SIZE = 20\n",
    "\n",
    "    def __init__(self, player_name, local_data_file):\n",
    "        self.player_name = player_name\n",
    "        self.local_data_file = local_data_file\n",
    "\n",
    "    def _build_data_pipeline(self):\n",
    "        \"\"\"Build a reproducible tf.data iterator.\"\"\"\n",
    "\n",
    "        def normalize(image, label):\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "            return image, label\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset([self.local_data_file])\n",
    "        dataset = dataset.map(decode)\n",
    "        dataset = dataset.map(normalize)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.batch(self.BATCH_SIZE)\n",
    "\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        return iterator\n",
    "\n",
    "    @tfe.local_computation\n",
    "    def provide_input(self) -> tf.Tensor:\n",
    "        \"\"\"Prepare input data for prediction.\"\"\"\n",
    "        with tf.name_scope('loading'):\n",
    "            prediction_input, expected_result = self._build_data_pipeline().get_next()\n",
    "            print_op = tf.print(\"Expect\", expected_result, summarize=self.BATCH_SIZE)\n",
    "            \n",
    "            with tf.control_dependencies([print_op]):\n",
    "                prediction_input = tf.identity(prediction_input)\n",
    "\n",
    "        with tf.name_scope('pre-processing'):\n",
    "            prediction_input = tf.reshape(\n",
    "                prediction_input, shape=(self.BATCH_SIZE, ModelOwner.FLATTENED_DIM))\n",
    "        \n",
    "        return prediction_input\n",
    "\n",
    "    @tfe.local_computation\n",
    "    def receive_output(self, logits: tf.Tensor) -> tf.Operation:\n",
    "        with tf.name_scope('post-processing'):\n",
    "            prediction = tf.argmax(logits, axis=1)\n",
    "            op = tf.print(\"Result\", prediction, summarize=self.BATCH_SIZE)\n",
    "            return op\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionClient():\n",
    "    \"\"\"Contains methods meant to be executed by a prediction client.\n",
    "\n",
    "    Args:\n",
    "    player_name: `str`, name of the `tfe.player.Player`\n",
    "                 representing the data owner\n",
    "    build_update_step: `Callable`, the function used to construct\n",
    "                       a local federated learning update.\n",
    "    \"\"\"\n",
    "\n",
    "    BATCH_SIZE = 20\n",
    "\n",
    "    def provide_input(self) -> List[tf.Tensor]:\n",
    "        \"\"\"Prepare input data for prediction.\"\"\"\n",
    "        with tf.name_scope('loading'):\n",
    "            prediction_input, expected_result = get_data_from_tfrecord(\"./data/test.tfrecord\", self.BATCH_SIZE, flattened=True).get_next()\n",
    "\n",
    "        with tf.name_scope('pre-processing'):\n",
    "            prediction_input = tf.reshape(\n",
    "            prediction_input, shape=(self.BATCH_SIZE, ModelTrainer.IN_N))\n",
    "            expected_result = tf.reshape(\n",
    "            expected_result, shape=(self.BATCH_SIZE,))\n",
    "\n",
    "        return [prediction_input, expected_result]\n",
    "\n",
    "    def receive_output(self, likelihoods: tf.Tensor, y_true: tf.Tensor):\n",
    "        with tf.name_scope('post-processing'):\n",
    "            prediction = tf.argmax(likelihoods, axis=1)\n",
    "            eq_values = tf.equal(prediction, tf.cast(y_true, tf.int64))\n",
    "            acc = tf.reduce_mean(tf.cast(eq_values, tf.float32))\n",
    "            op = tf.print('Expected:', y_true, '\\nActual:',prediction, '\\nAccuracy:', acc)\n",
    "\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if len(sys.argv) > 1:\n",
    "#    # config file was specified\n",
    "#    config_file = sys.argv[1]\n",
    "#    config = tfe.RemoteConfig.load(config_file)\n",
    "#    tfe.set_config(config)\n",
    "#    tfe.set_protocol(tfe.protocol.Pond())\n",
    "\n",
    "## set servers\n",
    "tfe.set_config(config)\n",
    "players = ['server0', 'server1', 'crypto-producer']\n",
    "prot = tfe.protocol.SecureNN(*tfe.get_config().get_players(players))\n",
    "tfe.set_protocol(prot)\n",
    "session_target = sys.argv[2] if len(sys.argv) > 2 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_data_from_tfrecord() got an unexpected keyword argument 'flattened'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a1dfde2b0b9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# get model parameters as private tensors from model owner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_private_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model-trainer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovide_input\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=E0632\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# we'll use the same parameters for each prediction so we cache them to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\protocol\\pond\\pond.py\u001b[0m in \u001b[0;36mdefine_private_input\u001b[1;34m(self, player, inputter_fn, apply_scaling, name_scope, masked, factory)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[0mname_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname_scope\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname_scope\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"private-input\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mmasked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmasked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[0mfactory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfactory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\protocol\\pond\\pond.py\u001b[0m in \u001b[0;36mdefine_local_computation\u001b[1;34m(self, player, computation_fn, arguments, apply_scaling, name_scope, masked, factory)\u001b[0m\n\u001b[0;32m    622\u001b[0m               reconstruct_input, arguments)\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5bbf426b43c4>\u001b[0m in \u001b[0;36mprovide_input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprovide_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loading'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_from_tfrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/train.tfrecord\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflattened\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_data_from_tfrecord() got an unexpected keyword argument 'flattened'"
     ]
    }
   ],
   "source": [
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "model_trainer = ModelTrainer()\n",
    "prediction_client = PredictionClient()\n",
    "\n",
    "# get model parameters as private tensors from model owner\n",
    "params = tfe.define_private_input('model-trainer', model_trainer.provide_input)  # pylint: disable=E0632\n",
    "\n",
    "# we'll use the same parameters for each prediction so we cache them to\n",
    "# avoid re-training each time\n",
    "cache_updater, params = tfe.cache(params)\n",
    "\n",
    "x, y = tfe.define_private_input('prediction-client', prediction_client.provide_input)  # pylint: disable=E0632\n",
    "\n",
    "with tfe.protocol.SecureNN():\n",
    "    # get prediction input from client\n",
    "    x = prediction_client.provide_input()\n",
    "    model = tfe.keras.Sequential()\n",
    "    model.add(tfe.keras.layers.Dense(512, batch_input_shape=x.shape))\n",
    "    model.add(tfe.keras.layers.Activation('relu'))\n",
    "    model.add(tfe.keras.layers.Dense(10, activation=None))\n",
    "\n",
    "    logits = model(x)\n",
    "\n",
    "# send prediction output back to client\n",
    "prediction_op = prediction_client.receive_output(logits)\n",
    "\n",
    "with tfe.Session(target=session_target) as sess:\n",
    "    sess.run(tf.global_variables_initializer(), tag='init')\n",
    "\n",
    "    print(\"Training\")\n",
    "    sess.run(cache_updater, tag='training')\n",
    "\n",
    "    print(\"Set trained weights\")\n",
    "    model.set_weights(params, sess)\n",
    "\n",
    "    for _ in range(5):\n",
    "        print(\"Predicting\")\n",
    "        sess.run(prediction_op, tag='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tf_encrypted:Players: ['server0', 'server1', 'server2', 'model-owner', 'prediction-client']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kg/miniconda3/envs/tfe/lib/python3.6/site-packages/tf_encrypted/config.py:171: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kg/miniconda3/envs/tfe/lib/python3.6/site-packages/tf_encrypted/config.py:171: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kg/miniconda3/envs/tfe/lib/python3.6/site-packages/tf_encrypted/config.py:84: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kg/miniconda3/envs/tfe/lib/python3.6/site-packages/tf_encrypted/config.py:84: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "No session factory registered for the given session options: {target: \"/home/kg/.local/share/jupyter/runtime/kernel-423cf829-fbee-4e9f-992e-8a10518319c1.json\" config: device_count { key: \"CPU\" value: 5 } graph_options { }} Registered factories are {DIRECT_SESSION, GRPC_SESSION}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8421195673f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprediction_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfe/lib/python3.6/site-packages/tf_encrypted/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, config, target, **tf_config_kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m       logger.info(\"Starting session on target '%s' using config %s\",\n\u001b[1;32m     53\u001b[0m                   self.target, self.config_proto)\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   def run(\n",
      "\u001b[0;32m~/miniconda3/envs/tfe/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0mprotocol\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mconfiguration\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \"\"\"\n\u001b[0;32m-> 1585\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tfe/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: No session factory registered for the given session options: {target: \"/home/kg/.local/share/jupyter/runtime/kernel-423cf829-fbee-4e9f-992e-8a10518319c1.json\" config: device_count { key: \"CPU\" value: 5 } graph_options { }} Registered factories are {DIRECT_SESSION, GRPC_SESSION}."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
