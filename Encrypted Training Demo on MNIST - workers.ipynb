{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 78s 1ms/sample - loss: 2.2643 - acc: 0.2379 - val_loss: 2.2085 - val_acc: 0.4433\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 79s 1ms/sample - loss: 2.1451 - acc: 0.5511 - val_loss: 2.0621 - val_acc: 0.6362\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 78s 1ms/sample - loss: 1.9603 - acc: 0.6595 - val_loss: 1.8229 - val_acc: 0.6973\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 79s 1ms/sample - loss: 1.6685 - acc: 0.7227 - val_loss: 1.4716 - val_acc: 0.7727\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 77s 1ms/sample - loss: 1.3002 - acc: 0.7836 - val_loss: 1.0976 - val_acc: 0.8146\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.9766 - acc: 0.8116 - val_loss: 0.8281 - val_acc: 0.8354\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 80s 1ms/sample - loss: 0.7682 - acc: 0.8298 - val_loss: 0.6698 - val_acc: 0.8501\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.6447 - acc: 0.8436 - val_loss: 0.5748 - val_acc: 0.8629\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 79s 1ms/sample - loss: 0.5674 - acc: 0.8553 - val_loss: 0.5137 - val_acc: 0.8724\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.5156 - acc: 0.8638 - val_loss: 0.4717 - val_acc: 0.8821\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.4787 - acc: 0.8712 - val_loss: 0.4408 - val_acc: 0.8857\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 78s 1ms/sample - loss: 0.4508 - acc: 0.8773 - val_loss: 0.4174 - val_acc: 0.8902\n",
      "Test loss: 0.4174158010482788\n",
      "Test accuracy: 0.8902\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "## normalise data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "#model definition\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save your model's weights for future private prediction\n",
    "model.save('short-conv-mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Secure Model Serving with Syft Keras\n",
    "Now that you have a trained model with normal Keras, you are ready to serve some private predictions. We can do that using Syft Keras.\n",
    "\n",
    "To secure and serve this model, we will need three TFEWorkers (servers). This is because TF Encrypted under the hood uses an encryption technique called multi-party computation (MPC). The idea is to split the model weights and input data into shares, then send a share of each value to the different servers. The key property is that if you look at the share on one server, it reveals nothing about the original value (input data or model weights).\n",
    "\n",
    "We'll define a Syft Keras model like we did in the previous notebook. However, there is a trick: before instantiating this model, we'll run hook = sy.KerasHook(tf.keras). This will add three important new methods to the Keras Sequential class:\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "share: will secure your model via secret sharing; by default, it will use the SecureNN protocol from TF Encrypted to secret share your model between each of the three TFEWorkers. Most importantly, this will add the capability of providing predictions on encrypted data.\n",
    "    </li>\n",
    "    <li>\n",
    "serve: this function will launch a serving queue, so that the TFEWorkers can accept prediction requests on the secured model from external clients.\n",
    "    </li>\n",
    "    <li>\n",
    "shutdown_workers: once you are done providing private predictions, you can shut down your model by running this function. It will direct you to shutdown the server processes manually if you've opted to manually manage each worker.\n",
    "If you want to learn more about MPC, you can read this excellent blog.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD & SERVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Activation, Flatten, ReLU, Activation\n",
    "\n",
    "import syft as sy\n",
    "hook = sy.KerasHook(tf.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (1, 28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), batch_input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes, name=\"logit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING PRE-TRAINED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_weights = 'short-conv-mnist.h5'\n",
    "model.load_weights(pre_trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETTING UP WORKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = True\n",
    "\n",
    "alice = sy.TFEWorker(host='localhost:4000', auto_managed=AUTO)\n",
    "bob = sy.TFEWorker(host='localhost:4001', auto_managed=AUTO)\n",
    "carol = sy.TFEWorker(host='localhost:4002', auto_managed=AUTO)\n",
    "\n",
    "cluster = sy.TFECluster(alice, bob, carol)\n",
    "cluster.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if AUTO is True, there is no need to start servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the model into shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\keras\\engine\\base_layer_utils.py:29: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\tensor\\native.py:415: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\tensor\\native.py:101: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\tensor\\shared.py:62: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "ksizes is deprecated, use sizes instead\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\protocol\\securenn\\odd_tensor.py:318: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\keras\\model\\sequential.py:54: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\config.py:297: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\tf_encrypted\\config.py:84: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.share(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Served encrypted prediction 1 to client.\n",
      "Served encrypted prediction 2 to client.\n",
      "Served encrypted prediction 3 to client.\n"
     ]
    }
   ],
   "source": [
    "## limiting the number of requests to 3 unless otherwise stated for testing\n",
    "## to set no limit depending on requirement\n",
    "\n",
    "model.serve(num_requests=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stop()\n",
    "cluster.stop()\n",
    "\n",
    "if not AUTO:\n",
    "    process_ids = !ps aux | grep '[p]ython -m tf_encrypted.player --config' | awk '{print $2}'\n",
    "    for process_id in process_ids:\n",
    "        !kill {process_id}\n",
    "        print(\"Process ID {id} has been killed.\".format(id=process_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
